from nltk.tokenize import RegexpTokenizer
from nltk.tokenize import TreebankWordTokenizer
from nltk.tokenize.casual import casual_tokenize
from nltk.util import ngrams


# TODO: Bridge implementation
# RegexpTokenizer
# TreebankWordTokenizer
# casual_tokenize

class Tokenizer:
    pass

# Search about n-gram's
